\section{Concorrenza}
Gli algoritmi hanno e devono avere sempre una struttura molto semplice per evitare che si verifichino \textit{race conditions}, gestendo nella maniera migliore possibile gli accessi (anche simultanei) alle risorse condivise tra diversi clienti. \\
Questo richiede coordinazione e sincronizzazione per evitare che accessi simultanei, facendo in modo tale che qualcuno si \textit{blocchi}, fino a che il thread che ha acceduto non ha finito di usare la risorsa. \\
In questi casi, i thread non sono utili ai fini del parallelismo, ma per avere maggiore responsività nella struttura del codice (come la risposta a eventi \textit{GUI}), maggior sfruttamento della \textit{CPU} e isolamento degli errori. \\

\subsection{Condivisione}
E' molto comune nei programmi concorrenti che diversi thread possano accedere alle stesse risorse in memoria, ma questo può causare sovrapposizioni nell'accesso e modifica delle stesse. \\
Si introduce quindi la \textit{mutua esclusione} nella \textit{sezione critica} (ovvero dove si accede/modifica quella risorsa di memoria), utilizzabile attraverso il linguaggio in uso.
Una soluzione di base sono i \textit{lock}, che seguono tre fasi fondamentali:
\begin{itemize}
	\item \textit{new}: crea un nuovo \textit{lock}, con stato \textit{not held};
	\item \textit{acquire}: acquisice un \textit{lock}, portandolo allo stato \textit{held};
	\item \textit{release}: porta il \textit{lock} di nuovo a \textit{not held}.
\end{itemize}
Quindi l'istanza \textit{lock} sarà posta ai margini della \textit{sezione critica} nel codice, prima chiamando l'\textit{acquire()} e dopo il \textit{release()}. \\
In ogni caso, l'uso dei \textit{lock} non è granché comodo, perché prevede che si tenga sempre conto dello stato del \textit{lock}, causa scarsa performance e occorre sapre come gestire coerentemente i \textit{setters} e \textit{getters}. \\
Una parziale soluzione potrebbe essere usare il \textit{re-entrant lock} (o \textit{recursive lock}), che detiene sia il thread che lo sta bloccando e un contatore. L'\textit{acquire()} ha successo se e solo se il thread che lo vuole bloccare è lo stesso che lo sta richiedendo, in questo caso viene incrementato il contatore. Nel \textit{release()}, se il conteggio è $> 0$, il contatore viene decrementato, e una volta a $0$, lo stato del \textit{lock} viene posto a \textit{not held}.

\subsection{Java}
\textit{Java} supporta i re-entrant locks in maniera primitiva, tramite lo statement builtin \textit{synchronized}, che valuta l'espressione in input (perché ogni oggetto in \textit{Java}, ad eccezione dei primitivi, è un \textit{lock}), acquisisce il \textit{lock}, entrando nella parentesi graffa \textit{"\{"}, bloccandolo se necessario, e lo rilascia uscendo dalla parentesi graffa \textit{"\}"}.
\begin{lstlisting}
class BankAccount {

	private int balance = 0;
	private Object lk = new Object();

	int getBalance() {
		synchronized (lk) { return balance; }
	}

	void setBalance(int x){
		synchronized (lk) { balance = x; }
	}

	void withdraw(int amount) {
		synchronized (lk) {
			int b = getBalance();
			if (amount > b) {
				setBalance(b - amount);
			}
		}
	}
}
\end{lstlisting}

\newpage
Altro metodo di utilizzare il \textit{synchronized} è di porlo come scopo sul metodo:
\begin{lstlisting}
class BankAccount {

	private int balance = 0;

	synchronized int getBalance() { return balance; }
	synchronized void setBalance(int x) { balance = x; }

	synchronized void withdraw(int amount) {
		int b = getBalance();
		if(amount > b) {
			setBalance(b - amount);
		}
	}
}
\end{lstlisting}
I \textit{lock} sono privati, e in questo modo prevengono il fatto che il codice in altre classi possa eseguire operazioni sensibili. \\

Una \textit{race condition} si verifica quando il risultato computazionale dipende dallo scheduling, e quindi due thread si sovrappongono, e rappresenta un bug esistente solo a causa della concorrenza.
Due tipi di \textit{race condition} diversi sono i \textit{data races} e i \textit{bad interleavings}: la differenza sostanziale sta nel fatto che un \textit{data race} si verifica quando si presentano due accessi \textit{read/write} o \textit{write/write} alla stessa locazione di memoria simultaneamente. D'altra parte, una \textit{bad interleaving}, invece, è causata da l'esposizione in sezioni critiche di dati in uno stato intermedio inconsistente, nonostante la presenza di \textit{data race}. \\
E' quindi responsabilità del programmatore evitare che si verifichino \textit{data races}. \\

\subsubsection{Variabili volatili}
Oltre alle soluzioni già proposte, esiste poi un altro metodo, quello di utilizzare le variabili \textit{volatili}: questo sistema forza l'applicazione a non fare \textit{caching} delle variabili inizializzate come volatili, così da necessitare un accesso diretto alla memoria per ogni interazione con le suddette. E' un sistema intelligente e più efficiente rispetto alla \textit{synchronized}, ma da evitare in caso di lunghe sezioni critiche.

\subsection{Utilizzare correttamente i locks}
Per ogni locazione di memoria, occorre osservare almeno una delle seguenti regole:
\begin{enumerate}
	\item \textit{thread-local}: non utilizzare la variabile in più di un thread:
	dove possibile, sempre meglio evitare di condividere risorse, ma questo è possibile solo se il thread non deve comunicare attraverso di esse;
	\item \textit{immutabile}: non scrivere nella locazione di memoria:
	se il thread utilizza una locazione di variabili in lettura per tutta la sua esecuzione, allora è inutile complicarsi la vita, non c'è bisogno di sincronizzazione; in tal caso è utile passare nuovi oggetti ai thread;
	\item \textit{synchronized}: utilizzare la sincronizzazione per controllare gli accessi.
\end{enumerate}

Una volta appurato che rispettiamo adeguatamente le prime due regole, occorre sapere come mantenere i dati consistenti, evitando \textit{data races}:
\begin{enumerate}
	\item non permettere mai che due thread accedano simultaneamente in \textit{read/write} o \textit{write/write} alla stessa loaczione;
	\item per ciascuna locazione di memoria che necessita di sincronizzazione, controllare che sia sempre gestita nelle fasi di \textit{read} o \textit{write}, utilizzando \textit{lock guards};
	\item cominciare sempre con una politica di \textit{coarse-grained} e muoversi verso la \textit{fine-grained} soltanto se specificatamente richiesto e/o necessario. Esistono infatti due politiche di \textit{locking}:
	\begin{itemize}
		\item \textit{coarse-grained}: utilizzando meno \textit{locks}, ciascuno per più oggetti:
		\begin{itemize}
			\item è più semplice da implementare;
			\item più semplice gestire le operazioni che accedono alle locazioni di memoria.
		\end{itemize}
		\item \textit{fine-grained}: utilizzando più \textit{locks}, ciascuno per meno oggetti:
		\begin{itemize}
			\item più accessi contemporanei (più performante rispetto al \textit{coarse-grained}, che invece bloccherebbe anche quando non necessario).
		\end{itemize}
	\end{itemize}
	\item evitare di fare grandi computazioni o attività I/O nelle sezioni critiche, ma fare in ogni caso attenzione a dare - in questo modo - accessi alternati in lettura scrittura di tipo \textit{A-B-A};
	\item pensare sempre in termini di quali operazioni necessitano di essere atomiche, e formare le sezioni critiche limitatamente a quelle operazioni;
	\item utilizzare librerie builtin ogni volta che vengono in aiuto.
\end{enumerate}

\section{Deadlocks}
Una \textit{deadlock} si presenta quando ci sono $T_{1}, \ldots, T_{n}$ thread tali che:
\begin{itemize}
	\item per ciascuna $i = 1, \ldots, n-1$, $T_{i}$ è in attesa di una risorsa bloccata da $T_{i+1}$;
	\item $T_{n}$ è in attesa di una risorsa bloccata da $T_{1}$.
\end{itemize}
In altre parole, si tratta di un ciclo di attese; pertanto, evitare in programmazione di andarci incontro significa evitare che si presenti un possibile ciclo.
Quindi, ancora, occorre cercare di rendere le sezioni critiche più piccole possibile, utilizzare più possibile una granularità \textit{coarsen} dei locks e fare in modo tale che ogni lock venga acquisito sempre nello stesso ordine.

\section{Lock lettore/scrittore}
In questo caso il \textit{lock} può essere di tre tipi:
\begin{enumerate}
	\item non acquisito;
	\item acquisito per scrittura da un thread;
	\item acquisito per lettura da uno o più thread.
\end{enumerate}
Quindi, avrà i seguenti metodi:
\begin{itemize}
	\item \textit{new()}: inizializzerà un nuovo \textit{lock} con stato \textit{non acquisito};
	\item \textit{acquire\_write()}: attende se lo stato corrente del \textit{lock} è \textit{acquisito per lettura} o \textit{acquisito per scrittura}, altrimenti lo rende \textit{acquisito per scrittura};
	\item \textit{release\_write()}: rende lo stato del \textit{lock} \textit{non acquisito};
	\item \textit{acquire\_read()}: attende se lo stato corrente del \textit{lock} è \textit{acquisito per scrittura}, altrimenti lo rende/mantiene \textit{acquisito per lettura} e incrementa il numero di lettori;
	\item \textit{release\_read()}: decrementa il numero di lettori e, se questo è $0$, rende lo stato del \textit{lock} \textit{non acquisito}.
\end{itemize}

Quindi, nel problema \textit{lettore/scrittore}, tendenzialmente viene data la priorità agli scrittori.
Il \textit{synchronized} di \textit{Java} non supporta il lock \textit{lettore/scrittore}, ma esiste la libreria \textit{java.util.concurrent.locks.ReentrantReadWriteLock}:
\begin{itemize}
	\item non hanno stessa interfaccia: per questo i metodi \textit{readLock()} e \textit{writeLock()} ritornano oggetti che hanno a loro volta i metodi \textit{lock()} e \textit{unlock()};
	\item non d\`{a} priorità allo scrittore.
\end{itemize}

\section{Variabili condizione}
Si parte da un esempio canonico: la necessità di dover condividere lavoro tra thread, attraverso un coda di dimensione fissa, in cui i (thread) produttore accodano il risultato del loro lavoro e i (thread) consumatori lo prelevano per elaborarlo. \\
\newpage
Per fare in modo che questa logica funzioni, occorre \textit{sincronizzazione} nell'accesso alla coda:
\begin{lstlisting}
class Buffer<E> {

	E[] array = (E[]) new Object[SIZE];
	
	synchronized void enqueue(E elt) {
		if (isFull()) {
			...
		} else {
			/* add to array and adjust back */
		}
	}
	synchronized E dequeue(E elt) {
		if (isEmpty()) {
			...
		} else {
			/* take from array and adjust front */
		}
	}

}
\end{lstlisting}
Ma nei casi di \textit{isFull()} e \textit{isEmpty()}? La cosa migliore sarebbe lasciare in attesa il richiedente e notificarlo quando la risorsa richiesta è disponibile, senza lanciare eccezioni ma soprattutto, senza lasciare che la risorsa rimanga bloccata nel frattempo. \\
Per questa ragione vengono utilizzate le \textit{variabili condizione}, per notificare thread in attesa quando la condizione che causa la loro attesa è variata. Quindi:
\begin{lstlisting}
synchronized void enqueue(E elt) {
	if (isFull()) {
		this.wait(); // release lock and wait
	}
	/* add to array and adjust back */
	if (!isFull()) {
		this.notify(); // wake somebody up
	}
}
synchronized E dequeue(E elt) {
	if (isEmpty()) {
		this.wait(); // release lock and wait
	}
	/* take from array and adjust front */
	if (!isEmpty()) {
		this.notify(); // wake somebody up
	}
}
\end{lstlisting}

\paragraph{Java}
Per \textit{Java} ogni oggetto è una \textit{variabile condizione} (e un \textit{lock}). Altri linguaggi spesso usano diversificare i due concetti. \\\\

Nell'ultimo esempio, quindi, vengono introdotti \textit{wait()} e \textit{notify()}:
\begin{itemize}
	\item \textit{wait()}: registra il thread richiedente come interessato e poi \textit{atomicamente} rilascia il \textit{lock} sulla risorsa e blocca il thread; quando l'esecuzione riprenderà, la prima operazione sarà quella di riacquisire il \textit{lock};
	\item \textit{notify()}: prende uno dei thread in attesa e lo sveglia, se ce ne sono.
\end{itemize}

\paragraph{Problema \#1}
Nel tempo che intercorre tra la riattivazione di un thread e la sua riacquisizione del \textit{lock}, potrebbe essere che la \textit{variabile condizione} diventi falsa ancora. Per ovviare a questo problema, occorre ricontrollare sempre la condizione dopo aver ottenuto il \textit{lock}:
\begin{lstlisting}
synchronized void enqueue(E elt) {
	while (isFull()) {
		this.wait(); // release lock and wait
	}
	...
}
synchronized E dequeue(E elt) {
	while (isEmpty()) {
		this.wait(); // release lock and wait
	}
	...
}
\end{lstlisting}

\paragraph{Problema \#2}
Anche se ci sono più threads in attesa, ne viene svegliato sempre solo uno. La soluzione al problema è molto semplice: avvertire sempre tutti i thread, attraverso \textit{notifyAll()}:
\begin{lstlisting}
synchronized void enqueue(E elt) {
	...
	if (!isFull()) {
		this.notifyAll(); // wake everybody up
	}
}
synchronized E dequeue(E elt) {
	...
	if (!isEmpty()) {
		this.notifyAll(); // wake everybody up
	}
}
\end{lstlisting}
Altro approccio potrebbe essere chiamare, senza condizione \textit{if}, sempre il \textit{notifyAll()} (o \textit{notify()}), ma questo sarebbe utile soltanto se l'\textit{enqueuer} e il \textit{dequeuer} aspettassero su \textit{variabili condizione} diverse. \\
In ogni caso, \textit{Java} non sembra supportarlo, ma la classe \textit{ReentrantLock} di \textit{java.util.concurrent.locks} contiene un metodo \textit{newCondition()} che ritorna un nuovo oggetto \textit{Condition} associato al \textit{lock}.